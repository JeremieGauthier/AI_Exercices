{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Atari_Breakout.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPbomfuKdwp7CSH+Jnx3tPu",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JeremieGauthier/AI_Exercices/blob/master/Atari_Breakout.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dkxR9ko2hEcz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import cv2\n",
        "import gym\n",
        "import gym.spaces\n",
        "import numpy as np\n",
        "import collections\n",
        "\n",
        "\n",
        "class FireResetEnv(gym.Wrapper):\n",
        "    def __init__(self, env=None):\n",
        "        \"\"\"For environments where the user need to press FIRE for the game to start.\"\"\"\n",
        "        super(FireResetEnv, self).__init__(env)\n",
        "        assert env.unwrapped.get_action_meanings()[1] == 'FIRE'\n",
        "        assert len(env.unwrapped.get_action_meanings()) >= 3\n",
        "\n",
        "    def step(self, action):\n",
        "        return self.env.step(action)\n",
        "\n",
        "    def reset(self):\n",
        "        self.env.reset()\n",
        "        obs, _, done, _ = self.env.step(1)\n",
        "        if done:\n",
        "            self.env.reset()\n",
        "        obs, _, done, _ = self.env.step(2)\n",
        "        if done:\n",
        "            self.env.reset()\n",
        "        return obs\n",
        "\n",
        "\n",
        "class MaxAndSkipEnv(gym.Wrapper):\n",
        "    def __init__(self, env=None, skip=4):\n",
        "        \"\"\"Return only every `skip`-th frame\"\"\"\n",
        "        super(MaxAndSkipEnv, self).__init__(env)\n",
        "        # most recent raw observations (for max pooling across time steps)\n",
        "        self._obs_buffer = collections.deque(maxlen=2)\n",
        "        self._skip = skip\n",
        "\n",
        "    def step(self, action):\n",
        "        total_reward = 0.0\n",
        "        done = None\n",
        "        for _ in range(self._skip):\n",
        "            obs, reward, done, info = self.env.step(action)\n",
        "            self._obs_buffer.append(obs)\n",
        "            total_reward += reward\n",
        "            if done:\n",
        "                break\n",
        "        max_frame = np.max(np.stack(self._obs_buffer), axis=0)\n",
        "        return max_frame, total_reward, done, info\n",
        "\n",
        "    def reset(self):\n",
        "        \"\"\"Clear past frame buffer and init. to first obs. from inner env.\"\"\"\n",
        "        self._obs_buffer.clear()\n",
        "        obs = self.env.reset()\n",
        "        self._obs_buffer.append(obs)\n",
        "        return obs\n",
        "\n",
        "\n",
        "class ProcessFrame84(gym.ObservationWrapper):\n",
        "    def __init__(self, env=None):\n",
        "        super(ProcessFrame84, self).__init__(env)\n",
        "        self.observation_space = gym.spaces.Box(low=0, high=255, shape=(84, 84, 1), dtype=np.uint8)\n",
        "\n",
        "    def observation(self, obs):\n",
        "        return ProcessFrame84.process(obs)\n",
        "\n",
        "    @staticmethod\n",
        "    def process(frame):\n",
        "        if frame.size == 210 * 160 * 3:\n",
        "            img = np.reshape(frame, [210, 160, 3]).astype(np.float32)\n",
        "        elif frame.size == 250 * 160 * 3:\n",
        "            img = np.reshape(frame, [250, 160, 3]).astype(np.float32)\n",
        "        else:\n",
        "            assert False, \"Unknown resolution.\"\n",
        "        img = img[:, :, 0] * 0.299 + img[:, :, 1] * 0.587 + img[:, :, 2] * 0.114\n",
        "        resized_screen = cv2.resize(img, (84, 110), interpolation=cv2.INTER_AREA)\n",
        "        x_t = resized_screen[18:102, :]\n",
        "        x_t = np.reshape(x_t, [84, 84, 1])\n",
        "        return x_t.astype(np.uint8)\n",
        "\n",
        "\n",
        "class ImageToPyTorch(gym.ObservationWrapper):\n",
        "    def __init__(self, env):\n",
        "        super(ImageToPyTorch, self).__init__(env)\n",
        "        old_shape = self.observation_space.shape\n",
        "        self.observation_space = gym.spaces.Box(low=0.0, high=1.0, shape=(old_shape[-1], old_shape[0], old_shape[1]),\n",
        "                                                dtype=np.float32)\n",
        "\n",
        "    def observation(self, observation):\n",
        "        return np.moveaxis(observation, 2, 0)\n",
        "\n",
        "\n",
        "class ScaledFloatFrame(gym.ObservationWrapper):\n",
        "    def observation(self, obs):\n",
        "        return np.array(obs).astype(np.float32) / 255.0\n",
        "\n",
        "\n",
        "class BufferWrapper(gym.ObservationWrapper):\n",
        "    def __init__(self, env, n_steps, dtype=np.float32):\n",
        "        super(BufferWrapper, self).__init__(env)\n",
        "        self.dtype = dtype\n",
        "        old_space = env.observation_space\n",
        "        self.observation_space = gym.spaces.Box(old_space.low.repeat(n_steps, axis=0),\n",
        "                                                old_space.high.repeat(n_steps, axis=0), dtype=dtype)\n",
        "\n",
        "    def reset(self):\n",
        "        self.buffer = np.zeros_like(self.observation_space.low, dtype=self.dtype)\n",
        "        return self.observation(self.env.reset())\n",
        "\n",
        "    def observation(self, observation):\n",
        "        self.buffer[:-1] = self.buffer[1:]\n",
        "        self.buffer[-1] = observation\n",
        "        return self.buffer\n",
        "\n",
        "\n",
        "def make_env(env_name):\n",
        "    env = gym.make(env_name)\n",
        "    env = MaxAndSkipEnv(env)\n",
        "    env = FireResetEnv(env)\n",
        "    env = ProcessFrame84(env)\n",
        "    env = ImageToPyTorch(env)\n",
        "    env = BufferWrapper(env, 4)\n",
        "    return ScaledFloatFrame(env)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1RiIXp2Nhqap",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "def plot_learning_curve(x, scores, epsilons, filename):\n",
        "    \n",
        "    fig = plt.figure()\n",
        "    ax = fig.add_subplot(111, label=\"1\")\n",
        "    ax2 = fig.add_subplot(111, label=\"2\", frame_on=False)\n",
        "\n",
        "    ax.plot(x, epsilons, color=\"C0\")\n",
        "    ax.set_xlabel(\"Training Step\", color=\"C0\")\n",
        "    ax.set_ylabel(\"Epsilon\", color=\"C0\")\n",
        "    ax.tick_params(axis=\"x\", color=\"C0\")\n",
        "    ax.tick_params(axis=\"y\", color=\"C0\")\n",
        "\n",
        "    N = len(scores)\n",
        "    running_avg = np.empty(N)\n",
        "    for t in range(N):\n",
        "        running_avg[t] = np.mean(scores[max(0, t-100):(t+1)])\n",
        "\n",
        "    ax2.scatter(x, running_avg, color=\"C1\")\n",
        "    ax2.axes.get_xaxis().set_visible(False)\n",
        "    ax2.yaxis.tick_right()\n",
        "    ax2.set_ylabel(\"Score\", color=\"C1\")\n",
        "    ax2.yaxis.set_label_position(\"right\")\n",
        "    ax2.tick_params(axis='y', color=\"C1\")\n",
        "\n",
        "    plt.savefig(filename)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B6VTSJxshxUz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "74368e47-2035-4371-ecfd-fee5609a97a0"
      },
      "source": [
        "import gym\n",
        "import time\n",
        "import math\n",
        "import random\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "import torchvision.transforms as T\n",
        "import numpy as np\n",
        "\n",
        "from collections import namedtuple, deque\n",
        "from itertools import count\n",
        "\n",
        "\n",
        "Experience = namedtuple('Experience',\n",
        "                        ('state', 'action', 'reward', 'next_state'))\n",
        "\n",
        "class DQN(nn.Module):\n",
        "    def __init__(self, num_actions, lr, device):\n",
        "        super(DQN, self).__init__()\n",
        "\n",
        "        self.device = device\n",
        "        \n",
        "        self.conv1 = nn.Conv2d(\n",
        "            in_channels=4, out_channels=16, kernel_size=8, stride=4)\n",
        "        self.conv2 = nn.Conv2d(\n",
        "            in_channels=16, out_channels=32, kernel_size=4, stride=2)\n",
        "\n",
        "        # You have to respect the formula ((W-K+2P/S)+1)\n",
        "        self.fc = nn.Linear(in_features=32*9*9, out_features=256)\n",
        "        self.out = nn.Linear(in_features=256, out_features=num_actions)\n",
        "\n",
        "\n",
        "    def forward(self, state):\n",
        "        # (1) Hidden Conv. Layer\n",
        "        self.layer1 = F.relu(self.conv1(state.to(device)))\n",
        "\n",
        "        # (2) Hidden Conv. Layer\n",
        "        self.layer2 = F.relu(self.conv2(self.layer1))\n",
        "        \n",
        "        # (3) Hidden Linear Layer\n",
        "        input_layer3 = self.layer2.reshape(-1, 32*9*9)\n",
        "        self.layer3 = self.fc(input_layer3)\n",
        "\n",
        "        # (4) Output\n",
        "        actions = self.out(self.layer3)\n",
        "\n",
        "        return actions\n",
        "\n",
        "\n",
        "class ReplayMemory():\n",
        "    def __init__(self, capacity):\n",
        "        self.capacity = capacity\n",
        "        self.memory = []\n",
        "        self.count = 0\n",
        "\n",
        "    def add_to_memory(self, experience):\n",
        "        if len(self.memory) < self.capacity:\n",
        "            self.memory.append(experience)\n",
        "        else:\n",
        "            self.memory[self.capacity % self.count] = experience\n",
        "        self.count += 1\n",
        "\n",
        "    def extract_tensor(self, experiences):\n",
        "        batch = Experience(*zip(*experiences))\n",
        "\n",
        "        states = torch.cat(batch.state)\n",
        "        actions = torch.cat(batch.action)\n",
        "        rewards = torch.tensor(batch.reward)\n",
        "        #rewards = torch.cat(batch.reward)\n",
        "        next_actions = torch.cat(batch.next_state)\n",
        "\n",
        "        return (states, actions, rewards, next_actions)\n",
        "\n",
        "    def sample(self, batch_size):\n",
        "        return random.sample(self.memory, batch_size)\n",
        "\n",
        "    def can_provide_sample(self, batch_size):\n",
        "        return len(self.memory) >= batch_size\n",
        "\n",
        "\n",
        "class EpsilonGreedyStrategy():\n",
        "    def __init__(self, eps_start, eps_end, eps_decay):\n",
        "        self.eps_start = eps_start\n",
        "        self.eps_end = eps_end\n",
        "        self.eps_decay = eps_decay\n",
        "\n",
        "    def get_exploration_rate(self, current_step):\n",
        "        return self.eps_end + (self.eps_start - self.eps_end) * \\\n",
        "            math.exp(-1 * current_step * self.eps_decay)\n",
        "\n",
        "\n",
        "class Agent():\n",
        "    def __init__(self, num_actions, strategy, device):\n",
        "        self.strategy = strategy\n",
        "        self.num_actions = num_actions\n",
        "        self.current_step = 0\n",
        "        self.device = device\n",
        "\n",
        "    def choose_action(self, state, policy_net):\n",
        "        self.epsilon = self.strategy.get_exploration_rate(self.current_step)\n",
        "        self.current_step += 1\n",
        "\n",
        "        if np.random.random() < self.epsilon:  # Explore\n",
        "            action = random.randrange(self.num_actions)\n",
        "            return torch.tensor([action]).to(self.device)\n",
        "        else:  # Exploit\n",
        "            with torch.no_grad():\n",
        "                return policy_net(state).argmax(dim=1).to(self.device)\n",
        "\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "\n",
        "    lr = 0.001\n",
        "    gamma = 0.99\n",
        "    eps_start = 1\n",
        "    eps_end = 0.01\n",
        "    eps_decay = 0.001\n",
        "    target_update = 10\n",
        "    num_episodes = 1000\n",
        "    batch_size = 256\n",
        "    capacity = 1000000\n",
        "    max_nb_elements = 4\n",
        "\n",
        "    scores, eps_history = [], []\n",
        "\n",
        "\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "    env = make_env(\"Breakout-v0\")\n",
        "\n",
        "    strategy = EpsilonGreedyStrategy(eps_start, eps_end, eps_decay)\n",
        "\n",
        "    agent = Agent(env.action_space.n, strategy, device)\n",
        "    memory = ReplayMemory(capacity)\n",
        "\n",
        "    policy_network = DQN(env.action_space.n, lr, device).to(device)\n",
        "    target_network = DQN(env.action_space.n, lr, device).to(device)\n",
        "\n",
        "    target_network.load_state_dict(policy_network.state_dict())\n",
        "    target_network.eval()\n",
        "\n",
        "    optimizer = optim.Adam(params=policy_network.parameters(), lr=lr)\n",
        "    \n",
        "    for episode in range(num_episodes):\n",
        "        obs = env.reset()\n",
        "        state = env.observation(obs)\n",
        "        state = torch.tensor(state).unsqueeze(dim=0)\n",
        "        \n",
        "        score = 0\n",
        "        start = time.time()\n",
        "\n",
        "        for timestep in count():\n",
        "            action = agent.choose_action(state, policy_network)\n",
        "            next_state, reward, done, _ = env.step(action) \n",
        "            next_state = torch.tensor(next_state).unsqueeze(dim=0)\n",
        "            memory.add_to_memory(Experience(state, action, reward, next_state))\n",
        "            state = next_state\n",
        "            \n",
        "            score += reward\n",
        "\n",
        "            if memory.can_provide_sample(batch_size):\n",
        "                experiences = memory.sample(batch_size)\n",
        "                states, actions, rewards, next_states = memory.extract_tensor(experiences)\n",
        "\n",
        "                batch_index = np.arange(batch_size, dtype=np.int32)\n",
        "                current_q_value = policy_network.forward(states)[batch_index, actions.type(torch.LongTensor)]\n",
        "                next_q_value = target_network.forward(next_states)\n",
        "                target_q_value = rewards.to(device) + gamma * torch.max(next_q_value, dim=1)[0]\n",
        "\n",
        "                loss = nn.MSELoss()\n",
        "                loss = loss(target_q_value, current_q_value).to(device)\n",
        "                optimizer.zero_grad()\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "\n",
        "            if done:\n",
        "                break\n",
        "\n",
        "        scores.append(score)\n",
        "        eps_history.append(agent.epsilon)\n",
        "\n",
        "        if episode % target_update == 0:\n",
        "            target_network.load_state_dict(policy_network.state_dict())\n",
        "\n",
        "        print(\"episode :\", episode, \"epsilon :\", agent.epsilon, \"score\", score,\n",
        "                \"time :\", time.time()-start)\n",
        "\n",
        "        if episode % 20 == 0:\n",
        "            avg_score = np.mean(scores[-20:])\n",
        "            print(\"episode\", episode, \"score %.1f average score %.1f epsilon %.2f\" %\n",
        "               (score, avg_score, agent.epsilon))\n",
        "    \n",
        "    filename = 'Atari_Breakout_DQN.png'\n",
        "    x = [i+1 for i in range(num_episodes)]\n",
        "    plot_learning_curve(x, scores, eps_history, filename)\n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
            "  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "episode : 0 epsilon : 0.9507758838271028 score 1.0 time : 0.1622023582458496\n",
            "episode 0 score 1.0 average score 1.0 epsilon 0.95\n",
            "episode : 1 epsilon : 0.9075824147163817 score 0.0 time : 0.14638876914978027\n",
            "episode : 2 epsilon : 0.8402318035037033 score 2.0 time : 0.2421424388885498\n",
            "episode : 3 epsilon : 0.7522639763166509 score 4.0 time : 1.7442529201507568\n",
            "episode : 4 epsilon : 0.7118396387690156 score 0.0 time : 2.3819708824157715\n",
            "episode : 5 epsilon : 0.6540040037760834 score 3.0 time : 3.7752678394317627\n",
            "episode : 6 epsilon : 0.5944697016008592 score 3.0 time : 4.254587888717651\n",
            "episode : 7 epsilon : 0.5549559376949149 score 0.0 time : 3.017728328704834\n",
            "episode : 8 epsilon : 0.5211713940817868 score 2.0 time : 2.763587236404419\n",
            "episode : 9 epsilon : 0.4880450348059175 score 0.0 time : 2.891465425491333\n",
            "episode : 10 epsilon : 0.4486513662013461 score 2.0 time : 3.715885639190674\n",
            "episode : 11 epsilon : 0.4214571745478475 score 2.0 time : 2.801426887512207\n",
            "episode : 12 epsilon : 0.3902028564815819 score 2.0 time : 3.4166388511657715\n",
            "episode : 13 epsilon : 0.3691373633887137 score 1.0 time : 2.480664014816284\n",
            "episode : 14 epsilon : 0.345192483063627 score 2.0 time : 2.978825092315674\n",
            "episode : 15 epsilon : 0.32159521047435413 score 2.0 time : 3.187342405319214\n",
            "episode : 16 epsilon : 0.29821448517012433 score 2.0 time : 3.390288829803467\n",
            "episode : 17 epsilon : 0.27340820604386856 score 3.0 time : 3.9171462059020996\n",
            "episode : 18 epsilon : 0.258316698889083 score 1.0 time : 2.5469560623168945\n",
            "episode : 19 epsilon : 0.24549859399199161 score 1.0 time : 2.297525405883789\n",
            "episode : 20 epsilon : 0.23245057522899001 score 1.0 time : 2.4553656578063965\n",
            "episode 20 score 1.0 average score 1.6 epsilon 0.23\n",
            "episode : 21 epsilon : 0.21432358601999785 score 2.0 time : 3.673816204071045\n",
            "episode : 22 epsilon : 0.19842592204098175 score 3.0 time : 3.5251646041870117\n",
            "episode : 23 epsilon : 0.18568716522109138 score 2.0 time : 3.045485496520996\n",
            "episode : 24 epsilon : 0.16865070204357804 score 2.0 time : 4.411030292510986\n",
            "episode : 25 epsilon : 0.15616044302023793 score 3.0 time : 3.5614733695983887\n",
            "episode : 26 epsilon : 0.14792429437338672 score 1.0 time : 2.5195152759552\n",
            "episode : 27 epsilon : 0.1393736776789848 score 1.0 time : 2.767117500305176\n",
            "episode : 28 epsilon : 0.13002558676904785 score 2.0 time : 3.265779733657837\n",
            "episode : 29 epsilon : 0.11465873803664578 score 6.0 time : 6.000154733657837\n",
            "episode : 30 epsilon : 0.10777852216211022 score 2.0 time : 2.9767978191375732\n",
            "episode : 31 epsilon : 0.10319601312321383 score 0.0 time : 2.0906896591186523\n",
            "episode : 32 epsilon : 0.09577305759429164 score 3.0 time : 3.5970351696014404\n",
            "episode : 33 epsilon : 0.09102072151500111 score 2.0 time : 2.4958603382110596\n",
            "episode : 34 epsilon : 0.08714640214114173 score 1.0 time : 2.1165573596954346\n",
            "episode : 35 epsilon : 0.08214694508279297 score 2.0 time : 2.946971893310547\n",
            "episode : 36 epsilon : 0.07713496143793322 score 2.0 time : 3.1632847785949707\n",
            "episode : 37 epsilon : 0.07456709677144624 score 0.0 time : 1.7324457168579102\n",
            "episode : 38 epsilon : 0.07147957114518838 score 1.0 time : 2.2162320613861084\n",
            "episode : 39 epsilon : 0.06912802114689942 score 0.0 time : 1.7242860794067383\n",
            "episode : 40 epsilon : 0.06507549845525121 score 2.0 time : 3.090808391571045\n",
            "episode 40 score 2.0 average score 1.9 epsilon 0.07\n",
            "episode : 41 epsilon : 0.06249431841783484 score 1.0 time : 2.081631898880005\n",
            "episode : 42 epsilon : 0.05923993312288716 score 2.0 time : 2.853515863418579\n",
            "episode : 43 epsilon : 0.05540875569308094 score 3.0 time : 3.6012134552001953\n",
            "episode : 44 epsilon : 0.053107842586858134 score 1.0 time : 2.293732166290283\n",
            "episode : 45 epsilon : 0.05003303319298111 score 3.0 time : 3.278487205505371\n",
            "episode : 46 epsilon : 0.04755118528139592 score 2.0 time : 2.8470215797424316\n",
            "episode : 47 epsilon : 0.04466411295944983 score 3.0 time : 3.522414207458496\n",
            "episode : 48 epsilon : 0.042678093933699694 score 1.0 time : 2.6115498542785645\n",
            "episode : 49 epsilon : 0.040499336922423565 score 2.0 time : 3.0409812927246094\n",
            "episode : 50 epsilon : 0.03835220891832125 score 2.0 time : 3.229471206665039\n",
            "episode : 51 epsilon : 0.036356236943536124 score 3.0 time : 3.2109618186950684\n",
            "episode : 52 epsilon : 0.03497074508687494 score 1.0 time : 2.3662033081054688\n",
            "episode : 53 epsilon : 0.03302786358978751 score 3.0 time : 3.5952436923980713\n",
            "episode : 54 epsilon : 0.03210281427394234 score 0.0 time : 1.8052709102630615\n",
            "episode : 55 epsilon : 0.03038307588660147 score 3.0 time : 3.551147222518921\n",
            "episode : 56 epsilon : 0.029234488488991746 score 2.0 time : 2.615601062774658\n",
            "episode : 57 epsilon : 0.028223371946610044 score 1.0 time : 2.4134833812713623\n",
            "episode : 58 epsilon : 0.027213689064628115 score 1.0 time : 2.571011543273926\n",
            "episode : 59 epsilon : 0.026276216683654444 score 1.0 time : 2.5105457305908203\n",
            "episode : 60 epsilon : 0.025085061403883134 score 3.0 time : 3.429806709289551\n",
            "episode 60 score 3.0 average score 1.9 epsilon 0.03\n",
            "episode : 61 epsilon : 0.024220789498591133 score 1.0 time : 2.611393928527832\n",
            "episode : 62 epsilon : 0.023339171646952574 score 2.0 time : 2.8185312747955322\n",
            "episode : 63 epsilon : 0.02249970373876564 score 2.0 time : 2.842285394668579\n",
            "episode : 64 epsilon : 0.021469656042652302 score 4.0 time : 3.760718584060669\n",
            "episode : 65 epsilon : 0.01963791638985001 score 4.0 time : 7.727842569351196\n",
            "episode : 66 epsilon : 0.01905851267914338 score 2.0 time : 2.753086566925049\n",
            "episode : 67 epsilon : 0.01848843749821693 score 2.0 time : 2.903773546218872\n",
            "episode : 68 epsilon : 0.018163760783454747 score 0.0 time : 1.7594194412231445\n",
            "episode : 69 epsilon : 0.01703364415244793 score 2.0 time : 6.669878959655762\n",
            "episode : 70 epsilon : 0.01607210263609781 score 6.0 time : 6.634269952774048\n",
            "episode : 71 epsilon : 0.015816536276774134 score 0.0 time : 1.9295952320098877\n",
            "episode : 72 epsilon : 0.015588466627170961 score 0.0 time : 1.7908999919891357\n",
            "episode : 73 epsilon : 0.015226307172561009 score 2.0 time : 2.9876468181610107\n",
            "episode : 74 epsilon : 0.014795629312126479 score 4.0 time : 3.8664660453796387\n",
            "episode : 75 epsilon : 0.014552629340679576 score 1.0 time : 2.328500986099243\n",
            "episode : 76 epsilon : 0.014135899934505994 score 2.0 time : 4.314671754837036\n",
            "episode : 77 epsilon : 0.013716212272072557 score 4.0 time : 4.807891130447388\n",
            "episode : 78 epsilon : 0.013503298464507485 score 2.0 time : 2.63136887550354\n",
            "episode : 79 epsilon : 0.013224264760863965 score 3.0 time : 3.7707271575927734\n",
            "episode : 80 epsilon : 0.013015316932199249 score 2.0 time : 3.0224900245666504\n",
            "episode 80 score 2.0 average score 2.2 epsilon 0.01\n",
            "episode : 81 epsilon : 0.01275028610136944 score 4.0 time : 4.136711835861206\n",
            "episode : 82 epsilon : 0.012449061630248889 score 6.0 time : 5.228400945663452\n",
            "episode : 83 epsilon : 0.012227110361392981 score 4.0 time : 4.254262208938599\n",
            "episode : 84 epsilon : 0.012105820006644067 score 2.0 time : 2.5491068363189697\n",
            "episode : 85 epsilon : 0.0119991157206825 score 1.0 time : 2.3543436527252197\n",
            "episode : 86 epsilon : 0.011903520265317501 score 1.0 time : 2.233780860900879\n",
            "episode : 87 epsilon : 0.011731009809491523 score 4.0 time : 4.276850461959839\n",
            "episode : 88 epsilon : 0.011552249149158875 score 4.0 time : 4.910047292709351\n",
            "episode : 89 epsilon : 0.011458932411330456 score 2.0 time : 2.791769027709961\n",
            "episode : 90 epsilon : 0.01136711809392451 score 2.0 time : 2.9163992404937744\n",
            "episode : 91 epsilon : 0.01128108188441119 score 1.0 time : 2.9337775707244873\n",
            "episode : 92 epsilon : 0.011188515373715988 score 3.0 time : 3.3399431705474854\n",
            "episode : 93 epsilon : 0.01111149387421418 score 2.0 time : 2.956996202468872\n",
            "episode : 94 epsilon : 0.011031181201896292 score 2.0 time : 3.3219778537750244\n",
            "episode : 95 epsilon : 0.010951900223557085 score 4.0 time : 3.6170077323913574\n",
            "episode : 96 epsilon : 0.010864767099989368 score 4.0 time : 4.3314902782440186\n",
            "episode : 97 epsilon : 0.010803084727525345 score 3.0 time : 3.2876338958740234\n",
            "episode : 98 epsilon : 0.010723760272418456 score 4.0 time : 4.5692384243011475\n",
            "episode : 99 epsilon : 0.010667447157342531 score 3.0 time : 3.558687448501587\n",
            "episode : 100 epsilon : 0.010626695152419135 score 2.0 time : 2.7621119022369385\n",
            "episode 100 score 2.0 average score 2.9 epsilon 0.01\n",
            "episode : 101 epsilon : 0.010564229013908884 score 4.0 time : 4.6149373054504395\n",
            "episode : 102 epsilon : 0.01052345979245155 score 3.0 time : 3.254636526107788\n",
            "episode : 103 epsilon : 0.01049002686792958 score 2.0 time : 2.8750710487365723\n",
            "episode : 104 epsilon : 0.010444726827156166 score 4.0 time : 4.252172231674194\n",
            "episode : 105 epsilon : 0.010384314113499866 score 7.0 time : 6.359529495239258\n",
            "episode : 106 epsilon : 0.010348786581948589 score 4.0 time : 4.221572399139404\n",
            "episode : 107 epsilon : 0.010326836557606639 score 2.0 time : 2.8338828086853027\n",
            "episode : 108 epsilon : 0.010311830640684312 score 1.0 time : 2.052640199661255\n",
            "episode : 109 epsilon : 0.0102922063474694 score 2.0 time : 2.846489191055298\n",
            "episode : 110 epsilon : 0.010264928564603069 score 4.0 time : 4.276276588439941\n",
            "episode : 111 epsilon : 0.010249001824092552 score 2.0 time : 2.6864893436431885\n",
            "episode : 112 epsilon : 0.010232400045813718 score 3.0 time : 3.034196138381958\n",
            "episode : 113 epsilon : 0.010216905163209338 score 3.0 time : 3.01373028755188\n",
            "episode : 114 epsilon : 0.010195675998418556 score 5.0 time : 4.505218744277954\n",
            "episode : 115 epsilon : 0.010181900570546016 score 3.0 time : 3.21647310256958\n",
            "episode : 116 epsilon : 0.010172856232347557 score 1.0 time : 2.2184369564056396\n",
            "episode : 117 epsilon : 0.010166577425959692 score 0.0 time : 1.6221446990966797\n",
            "episode : 118 epsilon : 0.010153156491987211 score 4.0 time : 3.6495656967163086\n",
            "episode : 119 epsilon : 0.0101443816617367 score 2.0 time : 2.579700231552124\n",
            "episode : 120 epsilon : 0.010133414419802436 score 3.0 time : 3.4632973670959473\n",
            "episode 120 score 3.0 average score 3.0 epsilon 0.01\n",
            "episode : 121 epsilon : 0.01012328025039413 score 4.0 time : 3.4385149478912354\n",
            "episode : 122 epsilon : 0.010115637491213093 score 2.0 time : 2.791741132736206\n",
            "episode : 123 epsilon : 0.010105052499675556 score 5.0 time : 4.189011812210083\n",
            "episode : 124 epsilon : 0.010094486807550183 score 5.0 time : 4.616765975952148\n",
            "episode : 125 epsilon : 0.010087835014725138 score 3.0 time : 3.173602342605591\n",
            "episode : 126 epsilon : 0.010083217713025653 score 1.0 time : 2.3522093296051025\n",
            "episode : 127 epsilon : 0.010078449901383056 score 2.0 time : 2.585031032562256\n",
            "episode : 128 epsilon : 0.010074029245316543 score 2.0 time : 2.536475896835327\n",
            "episode : 129 epsilon : 0.010069162597787997 score 3.0 time : 2.980309009552002\n",
            "episode : 130 epsilon : 0.010062393445020605 score 5.0 time : 4.485922336578369\n",
            "episode : 131 epsilon : 0.010058525363367274 score 2.0 time : 2.794194459915161\n",
            "episode : 132 epsilon : 0.010055671047714546 score 1.0 time : 2.181485652923584\n",
            "episode : 133 epsilon : 0.01005123691263103 score 3.0 time : 3.6214840412139893\n",
            "episode : 134 epsilon : 0.010045534042003356 score 6.0 time : 5.14951491355896\n",
            "episode : 135 epsilon : 0.010042498136253533 score 3.0 time : 2.9903411865234375\n",
            "episode : 136 epsilon : 0.010039863464276553 score 2.0 time : 2.800243854522705\n",
            "episode : 137 epsilon : 0.010037057109479186 score 3.0 time : 3.2187912464141846\n",
            "episode : 138 epsilon : 0.010034517285312263 score 2.0 time : 3.1140079498291016\n",
            "episode : 139 epsilon : 0.010032539678516797 score 2.0 time : 2.585523843765259\n",
            "episode : 140 epsilon : 0.010027645424141715 score 5.0 time : 7.092042446136475\n",
            "episode 140 score 5.0 average score 3.0 epsilon 0.01\n",
            "episode : 141 epsilon : 0.010026061528474614 score 2.0 time : 2.594557046890259\n",
            "episode : 142 epsilon : 0.010023487308750785 score 4.0 time : 4.551255464553833\n",
            "episode : 143 epsilon : 0.010021681518640479 score 3.0 time : 3.48686146736145\n",
            "episode : 144 epsilon : 0.01002015515772441 score 3.0 time : 3.1655447483062744\n",
            "episode : 145 epsilon : 0.010019133873043554 score 1.0 time : 2.2717669010162354\n",
            "episode : 146 epsilon : 0.010016868706551666 score 6.0 time : 5.526991128921509\n",
            "episode : 147 epsilon : 0.010015870471148769 score 2.0 time : 2.6616623401641846\n",
            "episode : 148 epsilon : 0.010014856837873213 score 2.0 time : 2.897555112838745\n",
            "episode : 149 epsilon : 0.010013362606175635 score 5.0 time : 4.655993700027466\n",
            "episode : 150 epsilon : 0.01001187529536093 score 4.0 time : 5.2183098793029785\n",
            "episode : 151 epsilon : 0.010010627661973474 score 6.0 time : 4.887450218200684\n",
            "episode : 152 epsilon : 0.010009378878773307 score 4.0 time : 5.475602865219116\n",
            "episode : 153 epsilon : 0.010008418740410495 score 5.0 time : 4.759729385375977\n",
            "episode : 154 epsilon : 0.010006735959214794 score 7.0 time : 9.762948513031006\n",
            "episode : 155 epsilon : 0.010006004205990805 score 5.0 time : 5.035327434539795\n",
            "episode : 156 epsilon : 0.010005492921273517 score 4.0 time : 4.009061574935913\n",
            "episode : 157 epsilon : 0.010005214588728245 score 1.0 time : 2.2947723865509033\n",
            "episode : 158 epsilon : 0.010004842640946945 score 3.0 time : 3.2961907386779785\n",
            "episode : 159 epsilon : 0.010004172269874432 score 6.0 time : 6.592036485671997\n",
            "episode : 160 epsilon : 0.01000377522590053 score 5.0 time : 4.386573314666748\n",
            "episode 160 score 5.0 average score 3.9 epsilon 0.01\n",
            "episode : 161 epsilon : 0.010003453748704344 score 3.0 time : 3.933338165283203\n",
            "episode : 162 epsilon : 0.010003207398659366 score 3.0 time : 3.2977001667022705\n",
            "episode : 163 epsilon : 0.010003020614302456 score 2.0 time : 2.665361166000366\n",
            "episode : 164 epsilon : 0.010002793960776081 score 3.0 time : 3.464465379714966\n",
            "episode : 165 epsilon : 0.010002618129737217 score 2.0 time : 2.8669769763946533\n",
            "episode : 166 epsilon : 0.010002366613953852 score 5.0 time : 4.498793840408325\n",
            "episode : 167 epsilon : 0.01000219561068034 score 3.0 time : 3.324669361114502\n",
            "episode : 168 epsilon : 0.010002026804109323 score 3.0 time : 3.530998706817627\n",
            "episode : 169 epsilon : 0.010001833928197146 score 4.0 time : 4.422913551330566\n",
            "episode : 170 epsilon : 0.01000157060394245 score 10.0 time : 6.862276554107666\n",
            "episode : 171 epsilon : 0.010001507511415575 score 0.0 time : 1.8234479427337646\n",
            "episode : 172 epsilon : 0.01000136815103952 score 4.0 time : 4.254145860671997\n",
            "episode : 173 epsilon : 0.01000127693186756 score 2.0 time : 3.0565075874328613\n",
            "episode : 174 epsilon : 0.01000118703692397 score 3.0 time : 3.2512118816375732\n",
            "episode : 175 epsilon : 0.010001097966927667 score 3.0 time : 3.4599711894989014\n",
            "episode : 176 epsilon : 0.010000988526549966 score 5.0 time : 4.6708173751831055\n",
            "episode : 177 epsilon : 0.010000899838678452 score 4.0 time : 4.178384065628052\n",
            "episode : 178 epsilon : 0.010000836490782377 score 3.0 time : 3.3357996940612793\n",
            "episode : 179 epsilon : 0.0100004441736107 score 4.0 time : 28.005613803863525\n",
            "episode : 180 epsilon : 0.010000409204692329 score 3.0 time : 3.608412265777588\n",
            "episode 180 score 3.0 average score 3.5 epsilon 0.01\n",
            "episode : 181 epsilon : 0.01000037698880841 score 3.0 time : 3.6367151737213135\n",
            "episode : 182 epsilon : 0.010000349748911421 score 3.0 time : 3.289761543273926\n",
            "episode : 183 epsilon : 0.010000316465901972 score 5.0 time : 4.430286169052124\n",
            "episode : 184 epsilon : 0.01000030133286005 score 1.0 time : 2.1856582164764404\n",
            "episode : 185 epsilon : 0.010000274298108201 score 4.0 time : 4.136482238769531\n",
            "episode : 186 epsilon : 0.010000253209067464 score 3.0 time : 3.534778594970703\n",
            "episode : 187 epsilon : 0.010000238224975191 score 2.0 time : 2.7292776107788086\n",
            "episode : 188 epsilon : 0.010000208975182542 score 6.0 time : 5.8115129470825195\n",
            "episode : 189 epsilon : 0.010000195432587912 score 2.0 time : 2.9685239791870117\n",
            "episode : 190 epsilon : 0.010000177543473685 score 4.0 time : 4.238903999328613\n",
            "episode : 191 epsilon : 0.010000161776459241 score 5.0 time : 4.078432321548462\n",
            "episode : 192 epsilon : 0.010000149787182165 score 3.0 time : 3.3769376277923584\n",
            "episode : 193 epsilon : 0.010000136895176934 score 4.0 time : 3.9244730472564697\n",
            "episode : 194 epsilon : 0.010000130349004223 score 1.0 time : 2.144597053527832\n",
            "episode : 195 epsilon : 0.010000121293775668 score 2.0 time : 3.1628458499908447\n",
            "episode : 196 epsilon : 0.010000112529510307 score 3.0 time : 3.28527569770813\n",
            "episode : 197 epsilon : 0.010000105553243264 score 2.0 time : 2.8000473976135254\n",
            "episode : 198 epsilon : 0.010000090216785438 score 9.0 time : 6.932197570800781\n",
            "episode : 199 epsilon : 0.010000074605594754 score 7.0 time : 8.442522287368774\n",
            "episode : 200 epsilon : 0.01000006832088486 score 4.0 time : 3.9186596870422363\n",
            "episode 200 score 4.0 average score 3.6 epsilon 0.01\n",
            "episode : 201 epsilon : 0.010000062440587279 score 4.0 time : 3.979106903076172\n",
            "episode : 202 epsilon : 0.010000056216791932 score 6.0 time : 4.646417140960693\n",
            "episode : 203 epsilon : 0.010000052363799382 score 2.0 time : 3.159088134765625\n",
            "episode : 204 epsilon : 0.010000048580173797 score 3.0 time : 3.320626735687256\n",
            "episode : 205 epsilon : 0.010000043519777985 score 5.0 time : 4.9311137199401855\n",
            "episode : 206 epsilon : 0.010000040537014747 score 2.0 time : 3.169929027557373\n",
            "episode : 207 epsilon : 0.010000035845409129 score 6.0 time : 5.479053497314453\n",
            "episode : 208 epsilon : 0.010000032924448624 score 4.0 time : 3.7964813709259033\n",
            "episode : 209 epsilon : 0.01000003103810059 score 2.0 time : 2.6350791454315186\n",
            "episode : 210 epsilon : 0.010000028140659874 score 4.0 time : 4.345407009124756\n",
            "episode : 211 epsilon : 0.0100000261073139 score 3.0 time : 3.327545404434204\n",
            "episode : 212 epsilon : 0.01000002463616539 score 2.0 time : 2.59190034866333\n",
            "episode : 213 epsilon : 0.010000023224679877 score 2.0 time : 2.621084213256836\n",
            "episode : 214 epsilon : 0.010000022091998875 score 1.0 time : 2.2224626541137695\n",
            "episode : 215 epsilon : 0.010000020210767383 score 4.0 time : 3.9907889366149902\n",
            "episode : 216 epsilon : 0.010000018397513159 score 4.0 time : 4.19140625\n",
            "episode : 217 epsilon : 0.010000017153727572 score 2.0 time : 3.112950325012207\n",
            "episode : 218 epsilon : 0.010000015803248198 score 3.0 time : 3.6466076374053955\n",
            "episode : 219 epsilon : 0.010000013711234058 score 5.0 time : 6.3003764152526855\n",
            "episode : 220 epsilon : 0.010000013068640444 score 1.0 time : 2.0941548347473145\n",
            "episode 220 score 1.0 average score 3.2 epsilon 0.01\n",
            "episode : 221 epsilon : 0.010000012258450073 score 2.0 time : 2.8221335411071777\n",
            "episode : 222 epsilon : 0.010000011498487456 score 2.0 time : 2.8221538066864014\n",
            "episode : 223 epsilon : 0.010000010603832593 score 3.0 time : 3.5657687187194824\n",
            "episode : 224 epsilon : 0.010000009877065971 score 3.0 time : 3.1232001781463623\n",
            "episode : 225 epsilon : 0.010000009017936164 score 4.0 time : 4.0063276290893555\n",
            "episode : 226 epsilon : 0.010000008341270152 score 3.0 time : 3.418806552886963\n",
            "episode : 227 epsilon : 0.01000000777734874 score 3.0 time : 3.052210807800293\n",
            "episode : 228 epsilon : 0.010000007464925874 score 0.0 time : 1.8129093647003174\n",
            "episode : 229 epsilon : 0.010000007186580742 score 0.0 time : 1.6761012077331543\n",
            "episode : 230 epsilon : 0.010000006502687163 score 4.0 time : 4.385368824005127\n",
            "episode : 231 epsilon : 0.010000006020772065 score 3.0 time : 3.390340805053711\n",
            "episode : 232 epsilon : 0.010000005323949958 score 5.0 time : 5.448757886886597\n",
            "episode : 233 epsilon : 0.01000000492446432 score 3.0 time : 3.4438424110412598\n",
            "episode : 234 epsilon : 0.010000004698369347 score 1.0 time : 2.054112672805786\n",
            "episode : 235 epsilon : 0.010000004429184587 score 2.0 time : 2.5904314517974854\n",
            "episode : 236 epsilon : 0.010000004113258354 score 3.0 time : 3.237682342529297\n",
            "episode : 237 epsilon : 0.010000003755477726 score 4.0 time : 3.9848341941833496\n",
            "episode : 238 epsilon : 0.0100000035085944 score 2.0 time : 2.962439775466919\n",
            "episode : 239 epsilon : 0.010000003364285142 score 0.0 time : 1.8402106761932373\n",
            "episode : 240 epsilon : 0.010000003074725107 score 4.0 time : 3.9534265995025635\n",
            "episode 240 score 4.0 average score 2.5 epsilon 0.01\n",
            "episode : 241 epsilon : 0.01000000282135002 score 4.0 time : 3.794666051864624\n",
            "episode : 242 epsilon : 0.010000002670365892 score 1.0 time : 2.4184317588806152\n",
            "episode : 243 epsilon : 0.01000000243565448 score 4.0 time : 4.05040168762207\n",
            "episode : 244 epsilon : 0.010000002226020587 score 4.0 time : 3.9824182987213135\n",
            "episode : 245 epsilon : 0.010000002040542086 score 4.0 time : 3.8079640865325928\n",
            "episode : 246 epsilon : 0.010000001891207476 score 3.0 time : 3.3252029418945312\n",
            "episode : 247 epsilon : 0.01000000174057497 score 4.0 time : 3.639866352081299\n",
            "episode : 248 epsilon : 0.010000001631036173 score 2.0 time : 2.855189085006714\n",
            "episode : 249 epsilon : 0.01000000151772955 score 3.0 time : 3.1787095069885254\n",
            "episode : 250 epsilon : 0.010000001352852736 score 3.0 time : 5.089868068695068\n",
            "episode : 251 epsilon : 0.010000001261391531 score 2.0 time : 3.098531723022461\n",
            "episode : 252 epsilon : 0.010000001201073213 score 1.0 time : 2.148712158203125\n",
            "episode : 253 epsilon : 0.010000001124361705 score 2.0 time : 2.9092214107513428\n",
            "episode : 254 epsilon : 0.010000001061003863 score 2.0 time : 2.556760787963867\n",
            "episode : 255 epsilon : 0.010000000975520115 score 3.0 time : 3.7051162719726562\n",
            "episode : 256 epsilon : 0.01000000086434395 score 4.0 time : 5.353924989700317\n",
            "episode : 257 epsilon : 0.010000000796295844 score 3.0 time : 3.6203372478485107\n",
            "episode : 258 epsilon : 0.010000000717641958 score 5.0 time : 4.5784912109375\n",
            "episode : 259 epsilon : 0.010000000665122199 score 3.0 time : 3.3151936531066895\n",
            "episode : 260 epsilon : 0.010000000598825826 score 4.0 time : 4.652703285217285\n",
            "episode 260 score 4.0 average score 3.0 epsilon 0.01\n",
            "episode : 261 epsilon : 0.010000000570761126 score 1.0 time : 2.13531756401062\n",
            "episode : 262 epsilon : 0.010000000526878926 score 3.0 time : 3.4843435287475586\n",
            "episode : 263 epsilon : 0.010000000491258654 score 3.0 time : 3.0757412910461426\n",
            "episode : 264 epsilon : 0.010000000447631692 score 4.0 time : 4.052515983581543\n",
            "episode : 265 epsilon : 0.010000000402208569 score 5.0 time : 4.666666269302368\n",
            "episode : 266 epsilon : 0.01000000037277342 score 3.0 time : 3.3464303016662598\n",
            "episode : 267 epsilon : 0.010000000340008556 score 1.0 time : 4.017005920410156\n",
            "episode : 268 epsilon : 0.010000000315440722 score 3.0 time : 3.287024736404419\n",
            "episode : 269 epsilon : 0.010000000287715107 score 4.0 time : 4.095274209976196\n",
            "episode : 270 epsilon : 0.010000000268800853 score 3.0 time : 3.0027897357940674\n",
            "episode : 271 epsilon : 0.010000000247391174 score 4.0 time : 3.6254806518554688\n",
            "episode : 272 epsilon : 0.010000000226777822 score 4.0 time : 3.791057825088501\n",
            "episode : 273 epsilon : 0.010000000203765695 score 5.0 time : 4.672772407531738\n",
            "episode : 274 epsilon : 0.010000000108632516 score 7.0 time : 27.46600604057312\n",
            "episode : 275 epsilon : 0.010000000100180222 score 3.0 time : 3.5231130123138428\n",
            "episode : 276 epsilon : 0.010000000091649433 score 3.0 time : 3.8743951320648193\n",
            "episode : 277 epsilon : 0.010000000087179637 score 1.0 time : 2.1935172080993652\n",
            "episode : 278 epsilon : 0.010000000082514232 score 1.0 time : 2.406733274459839\n",
            "episode : 279 epsilon : 0.010000000076475528 score 3.0 time : 3.311429023742676\n",
            "episode : 280 epsilon : 0.010000000071091714 score 3.0 time : 3.1918747425079346\n",
            "episode 280 score 3.0 average score 3.2 epsilon 0.01\n",
            "episode : 281 epsilon : 0.010000000067085691 score 2.0 time : 2.5158822536468506\n",
            "episode : 282 epsilon : 0.010000000061557443 score 3.0 time : 3.766467809677124\n",
            "episode : 283 epsilon : 0.010000000057972616 score 2.0 time : 2.621121883392334\n",
            "episode : 284 epsilon : 0.01000000005514526 score 1.0 time : 2.2049169540405273\n",
            "episode : 285 epsilon : 0.010000000051468541 score 2.0 time : 3.01666259765625\n",
            "episode : 286 epsilon : 0.01000000004818129 score 2.0 time : 2.9192392826080322\n",
            "episode : 287 epsilon : 0.01000000004372722 score 4.0 time : 4.293632984161377\n",
            "episode : 288 epsilon : 0.010000000040689528 score 2.0 time : 3.181769609451294\n",
            "episode : 289 epsilon : 0.010000000036196803 score 6.0 time : 5.181769132614136\n",
            "episode : 290 epsilon : 0.01000000003318078 score 4.0 time : 3.8670883178710938\n",
            "episode : 291 epsilon : 0.01000000003026436 score 3.0 time : 4.093530654907227\n",
            "episode : 292 epsilon : 0.010000000027084748 score 6.0 time : 4.9449803829193115\n",
            "episode : 293 epsilon : 0.01000000002515284 score 3.0 time : 3.2973222732543945\n",
            "episode : 294 epsilon : 0.010000000023288758 score 3.0 time : 3.40677547454834\n",
            "episode : 295 epsilon : 0.01000000002012516 score 8.0 time : 6.531441926956177\n",
            "episode : 296 epsilon : 0.010000000018485207 score 3.0 time : 3.78136944770813\n",
            "episode : 297 epsilon : 0.010000000017287278 score 2.0 time : 2.946898937225342\n",
            "episode : 298 epsilon : 0.01000000001542471 score 6.0 time : 5.045818328857422\n",
            "episode : 299 epsilon : 0.010000000013804172 score 5.0 time : 4.8861939907073975\n",
            "episode : 300 epsilon : 0.010000000013157222 score 1.0 time : 2.1385209560394287\n",
            "episode 300 score 1.0 average score 3.4 epsilon 0.01\n",
            "episode : 301 epsilon : 0.010000000012515536 score 1.0 time : 2.2111334800720215\n",
            "episode : 302 epsilon : 0.010000000011786688 score 2.0 time : 2.645568370819092\n",
            "episode : 303 epsilon : 0.010000000010935024 score 3.0 time : 3.2926666736602783\n",
            "episode : 304 epsilon : 0.01000000001022638 score 2.0 time : 2.95271897315979\n",
            "episode : 305 epsilon : 0.010000000009727636 score 1.0 time : 2.217073440551758\n",
            "episode : 306 epsilon : 0.010000000008908187 score 2.0 time : 3.8700430393218994\n",
            "episode : 307 epsilon : 0.010000000008567456 score 0.0 time : 1.7117323875427246\n",
            "episode : 308 epsilon : 0.010000000007900854 score 3.0 time : 3.5948708057403564\n",
            "episode : 309 epsilon : 0.01000000000722806 score 4.0 time : 3.942129373550415\n",
            "episode : 310 epsilon : 0.010000000006692388 score 3.0 time : 3.3884005546569824\n",
            "episode : 311 epsilon : 0.010000000006043425 score 5.0 time : 4.523844003677368\n",
            "episode : 312 epsilon : 0.010000000005413906 score 6.0 time : 4.8733391761779785\n",
            "episode : 313 epsilon : 0.010000000004893808 score 5.0 time : 4.509526014328003\n",
            "episode : 314 epsilon : 0.010000000004414837 score 5.0 time : 4.541945934295654\n",
            "episode : 315 epsilon : 0.010000000004042935 score 4.0 time : 3.928318977355957\n",
            "episode : 316 epsilon : 0.010000000003811302 score 2.0 time : 2.6116788387298584\n",
            "episode : 317 epsilon : 0.010000000003603736 score 2.0 time : 2.50498366355896\n",
            "episode : 318 epsilon : 0.010000000003215461 score 5.0 time : 5.063918590545654\n",
            "episode : 319 epsilon : 0.01000000000293871 score 4.0 time : 3.976895332336426\n",
            "episode : 320 epsilon : 0.010000000002688466 score 4.0 time : 3.9119069576263428\n",
            "episode 320 score 4.0 average score 3.1 epsilon 0.01\n",
            "episode : 321 epsilon : 0.010000000002420493 score 5.0 time : 4.571150302886963\n",
            "episode : 322 epsilon : 0.010000000002238869 score 2.0 time : 3.4090688228607178\n",
            "episode : 323 epsilon : 0.010000000002058486 score 4.0 time : 3.694915294647217\n",
            "episode : 324 epsilon : 0.010000000001948327 score 1.0 time : 2.3881113529205322\n",
            "episode : 325 epsilon : 0.010000000001807547 score 3.0 time : 3.2759532928466797\n",
            "episode : 326 epsilon : 0.010000000001663577 score 4.0 time : 3.6201953887939453\n",
            "episode : 327 epsilon : 0.010000000001582444 score 1.0 time : 2.2030062675476074\n",
            "episode : 328 epsilon : 0.010000000001452042 score 3.0 time : 3.7577614784240723\n",
            "episode : 329 epsilon : 0.010000000001304698 score 5.0 time : 4.685080051422119\n",
            "episode : 330 epsilon : 0.010000000001191212 score 4.0 time : 3.951791524887085\n",
            "episode : 331 epsilon : 0.01000000000112184 score 2.0 time : 2.6090290546417236\n",
            "episode : 332 epsilon : 0.010000000001044953 score 3.0 time : 3.1353843212127686\n",
            "episode : 333 epsilon : 0.010000000000274439 score 3.0 time : 59.11688733100891\n",
            "episode : 334 epsilon : 0.010000000000250317 score 4.0 time : 4.041292667388916\n",
            "episode : 335 epsilon : 0.010000000000235975 score 2.0 time : 2.6072335243225098\n",
            "episode : 336 epsilon : 0.010000000000213947 score 5.0 time : 4.310930013656616\n",
            "episode : 337 epsilon : 0.010000000000204123 score 1.0 time : 2.106320858001709\n",
            "episode : 338 epsilon : 0.01000000000017924 score 5.0 time : 5.752449989318848\n",
            "episode : 339 epsilon : 0.010000000000162346 score 4.0 time : 4.370255470275879\n",
            "episode : 340 epsilon : 0.010000000000152892 score 2.0 time : 2.63167142868042\n",
            "episode 340 score 2.0 average score 3.1 epsilon 0.01\n",
            "episode : 341 epsilon : 0.010000000000134388 score 7.0 time : 5.696609258651733\n",
            "episode : 342 epsilon : 0.010000000000122453 score 4.0 time : 4.097951889038086\n",
            "episode : 343 epsilon : 0.010000000000114518 score 3.0 time : 2.9756712913513184\n",
            "episode : 344 epsilon : 0.010000000000106882 score 2.0 time : 3.0530407428741455\n",
            "episode : 345 epsilon : 0.01000000000009906 score 3.0 time : 3.351884365081787\n",
            "episode : 346 epsilon : 0.010000000000091994 score 3.0 time : 3.3131110668182373\n",
            "episode : 347 epsilon : 0.010000000000084414 score 4.0 time : 3.808732748031616\n",
            "episode : 348 epsilon : 0.010000000000078002 score 3.0 time : 3.4566259384155273\n",
            "episode : 349 epsilon : 0.01000000000007136 score 4.0 time : 3.9293882846832275\n",
            "episode : 350 epsilon : 0.010000000000064312 score 5.0 time : 4.58981728553772\n",
            "episode : 351 epsilon : 0.010000000000058658 score 4.0 time : 4.047084331512451\n",
            "episode : 352 epsilon : 0.010000000000054911 score 2.0 time : 2.8958330154418945\n",
            "episode : 353 epsilon : 0.01000000000005069 score 3.0 time : 3.4986023902893066\n",
            "episode : 354 epsilon : 0.010000000000044466 score 10.0 time : 5.801630735397339\n",
            "episode : 355 epsilon : 0.010000000000041254 score 3.0 time : 3.349578857421875\n",
            "episode : 356 epsilon : 0.010000000000036261 score 6.0 time : 5.660419702529907\n",
            "episode : 357 epsilon : 0.010000000000034424 score 1.0 time : 2.3012654781341553\n",
            "episode : 358 epsilon : 0.010000000000031428 score 4.0 time : 4.020981073379517\n",
            "episode : 359 epsilon : 0.010000000000028667 score 4.0 time : 4.097881078720093\n",
            "episode : 360 epsilon : 0.0100000000000255 score 8.0 time : 5.157166481018066\n",
            "episode 360 score 8.0 average score 4.2 epsilon 0.01\n",
            "episode : 361 epsilon : 0.010000000000023993 score 2.0 time : 2.6973986625671387\n",
            "episode : 362 epsilon : 0.010000000000022349 score 2.0 time : 3.114621877670288\n",
            "episode : 363 epsilon : 0.01000000000002109 score 2.0 time : 2.5211546421051025\n",
            "episode : 364 epsilon : 0.010000000000019545 score 3.0 time : 3.3166658878326416\n",
            "episode : 365 epsilon : 0.010000000000017703 score 5.0 time : 4.308844804763794\n",
            "episode : 366 epsilon : 0.010000000000016277 score 7.0 time : 3.655585765838623\n",
            "episode : 367 epsilon : 0.01000000000001432 score 7.0 time : 5.61011266708374\n",
            "episode : 368 epsilon : 0.0100000000000133 score 2.0 time : 3.198214292526245\n",
            "episode : 369 epsilon : 0.010000000000012537 score 2.0 time : 2.5815236568450928\n",
            "episode : 370 epsilon : 0.010000000000011562 score 3.0 time : 3.532783031463623\n",
            "episode : 371 epsilon : 0.0100000000000109 score 2.0 time : 2.5635666847229004\n",
            "episode : 372 epsilon : 0.010000000000010225 score 2.0 time : 2.7833588123321533\n",
            "episode : 373 epsilon : 0.010000000000009439 score 3.0 time : 3.5636518001556396\n",
            "episode : 374 epsilon : 0.010000000000008549 score 4.0 time : 4.315701484680176\n",
            "episode : 375 epsilon : 0.010000000000007898 score 3.0 time : 3.4352738857269287\n",
            "episode : 376 epsilon : 0.010000000000007597 score 0.0 time : 1.7135851383209229\n",
            "episode : 377 epsilon : 0.010000000000006731 score 6.0 time : 5.278784275054932\n",
            "episode : 378 epsilon : 0.010000000000006276 score 3.0 time : 3.0582971572875977\n",
            "episode : 379 epsilon : 0.010000000000005923 score 1.0 time : 2.5355429649353027\n",
            "episode : 380 epsilon : 0.010000000000005461 score 4.0 time : 3.5382895469665527\n",
            "episode 380 score 4.0 average score 3.1 epsilon 0.01\n",
            "episode : 381 epsilon : 0.010000000000004903 score 5.0 time : 4.681444883346558\n",
            "episode : 382 epsilon : 0.010000000000004517 score 3.0 time : 3.5781140327453613\n",
            "episode : 383 epsilon : 0.010000000000004233 score 2.0 time : 2.8223445415496826\n",
            "episode : 384 epsilon : 0.010000000000003926 score 3.0 time : 3.269777536392212\n",
            "episode : 385 epsilon : 0.01000000000000378 score 0.0 time : 1.6647593975067139\n",
            "episode : 386 epsilon : 0.010000000000003543 score 2.0 time : 2.850999355316162\n",
            "episode : 387 epsilon : 0.010000000000003366 score 1.0 time : 2.2450695037841797\n",
            "episode : 388 epsilon : 0.01000000000000304 score 5.0 time : 4.47890567779541\n",
            "episode : 389 epsilon : 0.010000000000002826 score 2.0 time : 3.1994898319244385\n",
            "episode : 390 epsilon : 0.010000000000002719 score 0.0 time : 1.7100741863250732\n",
            "episode : 391 epsilon : 0.010000000000002514 score 3.0 time : 3.4213531017303467\n",
            "episode : 392 epsilon : 0.01000000000000229 score 3.0 time : 4.074496507644653\n",
            "episode : 393 epsilon : 0.010000000000002144 score 2.0 time : 2.878258466720581\n",
            "episode : 394 epsilon : 0.010000000000002021 score 2.0 time : 2.575275421142578\n",
            "episode : 395 epsilon : 0.01000000000000189 score 3.0 time : 2.9668784141540527\n",
            "episode : 396 epsilon : 0.01000000000000175 score 3.0 time : 3.3236396312713623\n",
            "episode : 397 epsilon : 0.010000000000001612 score 3.0 time : 3.6119134426116943\n",
            "episode : 398 epsilon : 0.010000000000001376 score 8.0 time : 6.977654218673706\n",
            "episode : 399 epsilon : 0.010000000000001306 score 1.0 time : 2.2261548042297363\n",
            "episode : 400 epsilon : 0.010000000000001215 score 3.0 time : 3.2339627742767334\n",
            "episode 400 score 3.0 average score 2.7 epsilon 0.01\n",
            "episode : 401 epsilon : 0.010000000000001131 score 3.0 time : 3.032745122909546\n",
            "episode : 402 epsilon : 0.010000000000001003 score 5.0 time : 5.2892467975616455\n",
            "episode : 403 epsilon : 0.010000000000000954 score 1.0 time : 2.1789398193359375\n",
            "episode : 404 epsilon : 0.010000000000000899 score 2.0 time : 2.599210262298584\n",
            "episode : 405 epsilon : 0.010000000000000822 score 4.0 time : 3.9372708797454834\n",
            "episode : 406 epsilon : 0.010000000000000757 score 3.0 time : 3.6262993812561035\n",
            "episode : 407 epsilon : 0.010000000000000684 score 5.0 time : 4.4591639041900635\n",
            "episode : 408 epsilon : 0.010000000000000614 score 5.0 time : 4.602071285247803\n",
            "episode : 409 epsilon : 0.010000000000000576 score 2.0 time : 2.9369332790374756\n",
            "episode : 410 epsilon : 0.010000000000000531 score 3.0 time : 3.522005319595337\n",
            "episode : 411 epsilon : 0.010000000000000493 score 2.0 time : 3.2610268592834473\n",
            "episode : 412 epsilon : 0.010000000000000446 score 4.0 time : 4.307920217514038\n",
            "episode : 413 epsilon : 0.010000000000000422 score 2.0 time : 2.5764739513397217\n",
            "episode : 414 epsilon : 0.01000000000000037 score 6.0 time : 5.658519744873047\n",
            "episode : 415 epsilon : 0.010000000000000338 score 4.0 time : 3.9271066188812256\n",
            "episode : 416 epsilon : 0.010000000000000318 score 2.0 time : 2.8554012775421143\n",
            "episode : 417 epsilon : 0.01000000000000029 score 4.0 time : 3.93884015083313\n",
            "episode : 418 epsilon : 0.010000000000000262 score 5.0 time : 4.538500070571899\n",
            "episode : 419 epsilon : 0.01000000000000024 score 4.0 time : 3.9514458179473877\n",
            "episode : 420 epsilon : 0.010000000000000227 score 1.0 time : 2.058152914047241\n",
            "episode 420 score 1.0 average score 3.4 epsilon 0.01\n",
            "episode : 421 epsilon : 0.010000000000000215 score 2.0 time : 2.619100570678711\n",
            "episode : 422 epsilon : 0.010000000000000203 score 1.0 time : 2.405712604522705\n",
            "episode : 423 epsilon : 0.010000000000000186 score 4.0 time : 4.07612156867981\n",
            "episode : 424 epsilon : 0.010000000000000174 score 2.0 time : 2.8392460346221924\n",
            "episode : 425 epsilon : 0.010000000000000158 score 4.0 time : 4.082600831985474\n",
            "episode : 426 epsilon : 0.010000000000000129 score 6.0 time : 9.282277584075928\n",
            "episode : 427 epsilon : 0.010000000000000118 score 3.0 time : 3.382840156555176\n",
            "episode : 428 epsilon : 0.010000000000000106 score 5.0 time : 4.788261890411377\n",
            "episode : 429 epsilon : 0.010000000000000099 score 2.0 time : 2.967026472091675\n",
            "episode : 430 epsilon : 0.010000000000000087 score 6.0 time : 5.931392192840576\n",
            "episode : 431 epsilon : 0.010000000000000026 score 4.0 time : 53.1940336227417\n",
            "episode : 432 epsilon : 0.010000000000000002 score 4.0 time : 105.6738166809082\n",
            "episode : 433 epsilon : 0.010000000000000002 score 2.0 time : 2.5695929527282715\n",
            "episode : 434 epsilon : 0.010000000000000002 score 4.0 time : 4.308993816375732\n",
            "episode : 435 epsilon : 0.010000000000000002 score 2.0 time : 3.177837371826172\n",
            "episode : 436 epsilon : 0.010000000000000002 score 1.0 time : 2.1610350608825684\n",
            "episode : 437 epsilon : 0.010000000000000002 score 3.0 time : 3.3099989891052246\n",
            "episode : 438 epsilon : 0.010000000000000002 score 7.0 time : 6.171980857849121\n",
            "episode : 439 epsilon : 0.010000000000000002 score 2.0 time : 2.7221803665161133\n",
            "episode : 440 epsilon : 0.010000000000000002 score 5.0 time : 4.709848880767822\n",
            "episode 440 score 5.0 average score 3.5 epsilon 0.01\n",
            "episode : 441 epsilon : 0.010000000000000002 score 3.0 time : 2.9587860107421875\n",
            "episode : 442 epsilon : 0.010000000000000002 score 1.0 time : 2.180657148361206\n",
            "episode : 443 epsilon : 0.010000000000000002 score 1.0 time : 2.1802725791931152\n",
            "episode : 444 epsilon : 0.010000000000000002 score 3.0 time : 3.3608920574188232\n",
            "episode : 445 epsilon : 0.01 score 8.0 time : 6.768225193023682\n",
            "episode : 446 epsilon : 0.01 score 4.0 time : 4.429485082626343\n",
            "episode : 447 epsilon : 0.01 score 2.0 time : 2.5850486755371094\n",
            "episode : 448 epsilon : 0.01 score 3.0 time : 3.98873233795166\n",
            "episode : 449 epsilon : 0.01 score 1.0 time : 2.452471971511841\n",
            "episode : 450 epsilon : 0.01 score 2.0 time : 2.8480377197265625\n",
            "episode : 451 epsilon : 0.01 score 4.0 time : 4.715227842330933\n",
            "episode : 452 epsilon : 0.01 score 6.0 time : 5.471277952194214\n",
            "episode : 453 epsilon : 0.01 score 1.0 time : 2.1013641357421875\n",
            "episode : 454 epsilon : 0.01 score 2.0 time : 2.644535541534424\n",
            "episode : 455 epsilon : 0.01 score 5.0 time : 4.814692258834839\n",
            "episode : 456 epsilon : 0.01 score 4.0 time : 4.0189385414123535\n",
            "episode : 457 epsilon : 0.01 score 5.0 time : 20.96283531188965\n",
            "episode : 458 epsilon : 0.01 score 2.0 time : 2.524881601333618\n",
            "episode : 459 epsilon : 0.01 score 4.0 time : 4.575570821762085\n",
            "episode : 460 epsilon : 0.01 score 2.0 time : 2.6097190380096436\n",
            "episode 460 score 2.0 average score 3.1 epsilon 0.01\n",
            "episode : 461 epsilon : 0.01 score 4.0 time : 3.9217193126678467\n",
            "episode : 462 epsilon : 0.01 score 1.0 time : 2.410829544067383\n",
            "episode : 463 epsilon : 0.01 score 0.0 time : 1.698150396347046\n",
            "episode : 464 epsilon : 0.01 score 5.0 time : 4.929273366928101\n",
            "episode : 465 epsilon : 0.01 score 2.0 time : 2.876469850540161\n",
            "episode : 466 epsilon : 0.01 score 3.0 time : 3.1769375801086426\n",
            "episode : 467 epsilon : 0.01 score 6.0 time : 5.137993574142456\n",
            "episode : 468 epsilon : 0.01 score 3.0 time : 3.8597054481506348\n",
            "episode : 469 epsilon : 0.01 score 2.0 time : 2.7933788299560547\n",
            "episode : 470 epsilon : 0.01 score 5.0 time : 4.427285194396973\n",
            "episode : 471 epsilon : 0.01 score 4.0 time : 4.295431613922119\n",
            "episode : 472 epsilon : 0.01 score 2.0 time : 2.722083806991577\n",
            "episode : 473 epsilon : 0.01 score 1.0 time : 2.3557474613189697\n",
            "episode : 474 epsilon : 0.01 score 0.0 time : 1.7009875774383545\n",
            "episode : 475 epsilon : 0.01 score 2.0 time : 2.898059844970703\n",
            "episode : 476 epsilon : 0.01 score 8.0 time : 16.480056047439575\n",
            "episode : 477 epsilon : 0.01 score 3.0 time : 3.591575860977173\n",
            "episode : 478 epsilon : 0.01 score 4.0 time : 4.188734769821167\n",
            "episode : 479 epsilon : 0.01 score 3.0 time : 3.5324583053588867\n",
            "episode : 480 epsilon : 0.01 score 0.0 time : 1.7036159038543701\n",
            "episode 480 score 0.0 average score 2.9 epsilon 0.01\n",
            "episode : 481 epsilon : 0.01 score 7.0 time : 5.386256694793701\n",
            "episode : 482 epsilon : 0.01 score 4.0 time : 3.9644346237182617\n",
            "episode : 483 epsilon : 0.01 score 1.0 time : 2.120607852935791\n",
            "episode : 484 epsilon : 0.01 score 4.0 time : 4.37113618850708\n",
            "episode : 485 epsilon : 0.01 score 4.0 time : 4.2144153118133545\n",
            "episode : 486 epsilon : 0.01 score 1.0 time : 2.0909454822540283\n",
            "episode : 487 epsilon : 0.01 score 2.0 time : 3.061392307281494\n",
            "episode : 488 epsilon : 0.01 score 3.0 time : 3.4832353591918945\n",
            "episode : 489 epsilon : 0.01 score 3.0 time : 3.092085123062134\n",
            "episode : 490 epsilon : 0.01 score 8.0 time : 6.0033485889434814\n",
            "episode : 491 epsilon : 0.01 score 2.0 time : 2.817657232284546\n",
            "episode : 492 epsilon : 0.01 score 2.0 time : 2.7835941314697266\n",
            "episode : 493 epsilon : 0.01 score 6.0 time : 24.734774351119995\n",
            "episode : 494 epsilon : 0.01 score 1.0 time : 2.1464054584503174\n",
            "episode : 495 epsilon : 0.01 score 3.0 time : 3.173124313354492\n",
            "episode : 496 epsilon : 0.01 score 2.0 time : 2.851594924926758\n",
            "episode : 497 epsilon : 0.01 score 4.0 time : 4.025068521499634\n",
            "episode : 498 epsilon : 0.01 score 7.0 time : 22.121018886566162\n",
            "episode : 499 epsilon : 0.01 score 2.0 time : 2.781812906265259\n",
            "episode : 500 epsilon : 0.01 score 3.0 time : 3.3174049854278564\n",
            "episode 500 score 3.0 average score 3.5 epsilon 0.01\n",
            "episode : 501 epsilon : 0.01 score 3.0 time : 3.6155409812927246\n",
            "episode : 502 epsilon : 0.01 score 4.0 time : 4.547471046447754\n",
            "episode : 503 epsilon : 0.01 score 3.0 time : 3.2220399379730225\n",
            "episode : 504 epsilon : 0.01 score 2.0 time : 2.8100523948669434\n",
            "episode : 505 epsilon : 0.01 score 2.0 time : 2.820859909057617\n",
            "episode : 506 epsilon : 0.01 score 1.0 time : 2.4737586975097656\n",
            "episode : 507 epsilon : 0.01 score 4.0 time : 4.272123098373413\n",
            "episode : 508 epsilon : 0.01 score 3.0 time : 8.67547869682312\n",
            "episode : 509 epsilon : 0.01 score 8.0 time : 5.219817638397217\n",
            "episode : 510 epsilon : 0.01 score 2.0 time : 3.185018539428711\n",
            "episode : 511 epsilon : 0.01 score 5.0 time : 4.605753660202026\n",
            "episode : 512 epsilon : 0.01 score 2.0 time : 3.187098503112793\n",
            "episode : 513 epsilon : 0.01 score 3.0 time : 3.1904985904693604\n",
            "episode : 514 epsilon : 0.01 score 2.0 time : 2.751953125\n",
            "episode : 515 epsilon : 0.01 score 3.0 time : 3.4073915481567383\n",
            "episode : 516 epsilon : 0.01 score 3.0 time : 7.930420637130737\n",
            "episode : 517 epsilon : 0.01 score 3.0 time : 3.2154126167297363\n",
            "episode : 518 epsilon : 0.01 score 3.0 time : 3.4122748374938965\n",
            "episode : 519 epsilon : 0.01 score 1.0 time : 2.13979172706604\n",
            "episode : 520 epsilon : 0.01 score 3.0 time : 3.44805645942688\n",
            "episode 520 score 3.0 average score 3.0 epsilon 0.01\n",
            "episode : 521 epsilon : 0.01 score 3.0 time : 5.727621078491211\n",
            "episode : 522 epsilon : 0.01 score 3.0 time : 3.452514171600342\n",
            "episode : 523 epsilon : 0.01 score 2.0 time : 3.142294406890869\n",
            "episode : 524 epsilon : 0.01 score 4.0 time : 4.186671495437622\n",
            "episode : 525 epsilon : 0.01 score 2.0 time : 2.8725855350494385\n",
            "episode : 526 epsilon : 0.01 score 5.0 time : 40.903435945510864\n",
            "episode : 527 epsilon : 0.01 score 6.0 time : 5.049980878829956\n",
            "episode : 528 epsilon : 0.01 score 2.0 time : 2.840090751647949\n",
            "episode : 529 epsilon : 0.01 score 3.0 time : 3.607395887374878\n",
            "episode : 530 epsilon : 0.01 score 3.0 time : 3.2676031589508057\n",
            "episode : 531 epsilon : 0.01 score 4.0 time : 4.1880202293396\n",
            "episode : 532 epsilon : 0.01 score 6.0 time : 4.956260919570923\n",
            "episode : 533 epsilon : 0.01 score 3.0 time : 3.568716049194336\n",
            "episode : 534 epsilon : 0.01 score 2.0 time : 2.4396169185638428\n",
            "episode : 535 epsilon : 0.01 score 1.0 time : 2.5146291255950928\n",
            "episode : 536 epsilon : 0.01 score 5.0 time : 4.8320066928863525\n",
            "episode : 537 epsilon : 0.01 score 6.0 time : 5.7293877601623535\n",
            "episode : 538 epsilon : 0.01 score 1.0 time : 2.3603079319000244\n",
            "episode : 539 epsilon : 0.01 score 3.0 time : 2.9973015785217285\n",
            "episode : 540 epsilon : 0.01 score 5.0 time : 5.014172792434692\n",
            "episode 540 score 5.0 average score 3.5 epsilon 0.01\n",
            "episode : 541 epsilon : 0.01 score 4.0 time : 4.443493366241455\n",
            "episode : 542 epsilon : 0.01 score 3.0 time : 3.2494425773620605\n",
            "episode : 543 epsilon : 0.01 score 3.0 time : 3.3932583332061768\n",
            "episode : 544 epsilon : 0.01 score 4.0 time : 3.7299559116363525\n",
            "episode : 545 epsilon : 0.01 score 4.0 time : 35.43990612030029\n",
            "episode : 546 epsilon : 0.01 score 3.0 time : 3.26809024810791\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-fb5e634502ac>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    173\u001b[0m                 \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget_q_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcurrent_q_value\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m                 \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 175\u001b[0;31m                 \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    176\u001b[0m                 \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    193\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m         \"\"\"\n\u001b[0;32m--> 195\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    196\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     97\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     98\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ]
}